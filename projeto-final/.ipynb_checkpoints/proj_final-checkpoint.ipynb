{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n",
      "/usr/lib/python3.6/importlib/_bootstrap.py:219: RuntimeWarning: numpy.dtype size changed, may indicate binary incompatibility. Expected 96, got 88\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import yaml\n",
    "\n",
    "mnist = tf.keras.datasets.mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data from mnist into train set and test set\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn data into one dimensional array (for KMeans fitting)\n",
    "train_set = x_train.copy()\n",
    "train_set = np.array([np.concatenate(i) for i in x_train])\n",
    "# print(train_set[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_clusters = len(set(y_train))\n",
    "classes = [[] for i in range(n_clusters)]\n",
    "for i in range(n_clusters):\n",
    "    classes[i] = train_set[np.where(y_train == i)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if classes are ok\n",
    "# plt.imshow(np.resize(classes[6][6],(28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[50, 60, 70, 80, 90, 100, 110, 120, 130, 140, 150]\n"
     ]
    }
   ],
   "source": [
    "print([i for i in ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1h 58min 17s, sys: 47min 52s, total: 2h 46min 9s\n",
      "Wall time: 1h 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Creates clusters in each class, reducing number of points of data set\n",
    "for new_data_len in range(50, 160, 10):\n",
    "    clustering = []\n",
    "#     new_data_len = 40\n",
    "    for item in classes:\n",
    "        clustering.append(KMeans(n_clusters = new_data_len, random_state = 0).fit(item))\n",
    "\n",
    "    with open(f'classes_{new_data_len}.yaml', 'w') as f:\n",
    "            yaml.dump(clustering, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-8-59c13d0de49d>, line 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-59c13d0de49d>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    %%time\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Load clusters (uncomment and run the lines below if clusters were already computed)\n",
    "\n",
    "new_data_len = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test if new classes are ok\n",
    "# plt.imshow(np.resize(new_x_train_set[99], (28,28)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_disp_matrix(dataset):\n",
    "    x = dataset - calc_mean(dataset)\n",
    "    return np.dot(x.T, x)\n",
    "\n",
    "def calc_cov_matrix(dataset):\n",
    "    n = len(dataset)\n",
    "    return calc_disp_matrix(dataset)/(n-1)\n",
    "\n",
    "def calc_mean(dataset):\n",
    "    return np.mean(dataset, axis=0)\n",
    "\n",
    "def log_discriminant(sample, class_mean, class_cov, class_prob):\n",
    "    cov_inv = np.linalg.inv(class_cov)\n",
    "    g = -0.5*np.dot(np.dot((sample - class_mean), cov_inv), (sample - class_mean).T) - 0.5*np.log(np.linalg.det(class_cov)) + np.log(class_prob)\n",
    "    \n",
    "    return g\n",
    "\n",
    "def bayesian_classifier(training_set, sample):\n",
    "    data = training_set[:, 0:-1]\n",
    "    labels = training_set[:,-1]\n",
    "    print(data)\n",
    "    print(labels)\n",
    "    \n",
    "    classes = set([int(i) for i in labels])\n",
    "    set_size = len(data)\n",
    "    g = [[] for i in classes]\n",
    "    \n",
    "    for i in classes:\n",
    "        p_priori = len(data[np.where(labels == i)])/set_size\n",
    "        g[i] = log_discriminant(sample, calc_mean(data[np.where(labels == i)]), calc_cov_matrix(data[np.where(labels == i)]), p_priori)\n",
    "#         print(f'g[{i}] = {g[i]}')\n",
    "#         print(g[i])\n",
    "    \n",
    "    return np.argmax(np.array(g))\n",
    "\n",
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def knn(dataset, sample, k):\n",
    "    #dataset: (attributes, class labels)\n",
    "    data = dataset[:, 0:-1]\n",
    "    labels = dataset[:, -1]\n",
    "    test_sample = np.array(sample)\n",
    "    \n",
    "    total_dist = data - test_sample                          # numpy automatically creates a repeated array of test_sample\n",
    "    norm = np.sum(total_dist*total_dist, axis=1)\n",
    "    neighbors = list(zip(norm, labels))                      # create list of tuples (square of distance, label of class)\n",
    "    neighbors = sorted(neighbors, key=lambda tup: tup[0])    # sort neighbors by distance\n",
    "    closest_n = [atribute[1] for atribute in neighbors[:k]]\n",
    "    return most_common(closest_n)\n",
    "\n",
    "def evaluate_error(classifier, training, test, extrArgs = []):\n",
    "    error_rate = 0\n",
    "    \n",
    "    for sample in test:\n",
    "        if classifier == knn:\n",
    "            n = classifier(training, sample[:-1], extrArgs[0])\n",
    "        else:\n",
    "            n = classifier(training, sample[:-1])\n",
    "        error_rate += not(n == sample[-1])\n",
    "        \n",
    "    return error_rate/len(test)\n",
    "\n",
    "def split_folds(dataset, k):\n",
    "    data_cpy = dataset.copy()\n",
    "    np.random.shuffle(data_cpy)            # desordena conjunto de dados\n",
    "    folds = np.split(data_cpy, k)          # divide os grupos\n",
    "    return folds\n",
    "\n",
    "def kfolds(classifier, dataset, k, extrArgs = []):\n",
    "    folds = split_folds(dataset, k)\n",
    "    error_array = []\n",
    "\n",
    "    for i, fold in enumerate(folds):\n",
    "        folds_cpy = folds.copy()           # cria c√≥pia dos grupos\n",
    "        test = folds_cpy.pop(i)            # separa grupo i para teste\n",
    "        training = np.vstack(folds_cpy)    # agrupa demais grupos para treinamento\n",
    "        error_array = np.append(error_array, evaluate_error(classifier, training, test, extrArgs))\n",
    "    \n",
    "    return np.mean(error_array), np.std(error_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K = 50, k = 5, KNN error rate (0.046000000000000006, 0.036932370625238777)\n",
      "K = 60, k = 5, KNN error rate (0.03333333333333333, 0.021081851067789197)\n",
      "K = 70, k = 5, KNN error rate (0.02285714285714286, 0.019378085666072194)\n",
      "K = 80, k = 5, KNN error rate (0.028750000000000005, 0.027414640249326636)\n",
      "K = 90, k = 5, KNN error rate (0.03, 0.013193713430042128)\n",
      "K = 100, k = 5, KNN error rate (0.027000000000000003, 0.019000000000000003)\n",
      "K = 110, k = 5, KNN error rate (0.030909090909090907, 0.01233150906022776)\n",
      "K = 120, k = 5, KNN error rate (0.028333333333333332, 0.011902380714238084)\n",
      "K = 130, k = 5, KNN error rate (0.02846153846153846, 0.008461538461538461)\n",
      "K = 140, k = 5, KNN error rate (0.02642857142857143, 0.014303560281786273)\n",
      "K = 150, k = 5, KNN error rate (0.030666666666666665, 0.012000000000000002)\n",
      "CPU times: user 1min 42s, sys: 253 ms, total: 1min 42s\n",
      "Wall time: 1min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for new_data_len in range(50, 160, 10):\n",
    "    new_x_train_set = []\n",
    "    new_y_train_set = []\n",
    "    i = 0\n",
    "\n",
    "    with open(f'classes_{new_data_len}.yaml', 'r') as f:\n",
    "        clustering = yaml.load(f)\n",
    "\n",
    "    for c in clustering:\n",
    "        new_x_train_set.append(c.cluster_centers_)\n",
    "        new_y_train_set.append([i for x in range(len(c.cluster_centers_))])\n",
    "        i += 1\n",
    "\n",
    "    new_x_train_set = np.concatenate(new_x_train_set)\n",
    "    new_y_train_set = np.concatenate(new_y_train_set)\n",
    "#     print(len(new_x_train_set))\n",
    "\n",
    "\n",
    "    training_set = np.hstack((new_x_train_set, np.resize(new_y_train_set, (new_x_train_set.shape[0], 1))))\n",
    "    # training_set = np.hstack((train_set, np.resize(y_train, (x_train.shape[0], 1))))\n",
    "\n",
    "    print(f'K = {new_data_len}, k = 5, KNN error rate {kfolds(knn, training_set, 10, [5])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(280000, 29)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.hstack((np.concatenate(x_test), np.resize(y_test, (np.concatenate(x_test).shape[0], 1)))).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (1500,784) (28,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<timed exec>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-df5ab73df0b1>\u001b[0m in \u001b[0;36mevaluate_error\u001b[0;34m(classifier, training, test, extrArgs)\u001b[0m\n\u001b[1;32m     55\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msample\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextrArgs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-9-df5ab73df0b1>\u001b[0m in \u001b[0;36mknn\u001b[0;34m(dataset, sample, k)\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mtest_sample\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mtotal_dist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_sample\u001b[0m                          \u001b[0;31m# numpy automatically creates a repeated array of test_sample\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m     \u001b[0mnorm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtotal_dist\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtotal_dist\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0mneighbors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m                      \u001b[0;31m# create list of tuples (square of distance, label of class)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (1500,784) (28,) "
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for new_data_len in range(50, 160, 10):\n",
    "    print(f'K={new_data_len}, {evaluate_error(knn, training_set, np.hstack((np.concatenate(x_test), np.resize(y_test, (np.concatenate(x_test).shape[0], 1)))), [5])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k = 1, KNN error rate (0.1, 0.035355339059327376)\n",
      "k = 2, KNN error rate (0.12250000000000001, 0.05857687256929991)\n",
      "k = 3, KNN error rate (0.06, 0.032015621187164243)\n",
      "k = 4, KNN error rate (0.05750000000000001, 0.0225)\n",
      "k = 5, KNN error rate (0.042499999999999996, 0.03363406011768428)\n",
      "k = 6, KNN error rate (0.05750000000000001, 0.0317214438511238)\n",
      "k = 7, KNN error rate (0.04, 0.03)\n",
      "k = 8, KNN error rate (0.042499999999999996, 0.0275)\n",
      "k = 9, KNN error rate (0.0475, 0.02839454172900137)\n",
      "k = 10, KNN error rate (0.0475, 0.0343693177121688)\n",
      "k = 11, KNN error rate (0.045000000000000005, 0.029154759474226504)\n",
      "CPU times: user 4.27 s, sys: 5.66 ms, total: 4.28 s\n",
      "Wall time: 4.27 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "char = 1340\n",
    "training_set = np.hstack((new_x_train_set, np.resize(new_y_train_set, (new_x_train_set.shape[0], 1))))\n",
    "# training_set = np.hstack((train_set, np.resize(y_train, (x_train.shape[0], 1))))\n",
    "\n",
    "for k in range(1,12):\n",
    "    print(f'k = {k}, KNN error rate {kfolds(knn, training_set, 10, [k])}')\n",
    "    \n",
    "# k = 5 apresentou os melhores resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success rate: 94.74\n"
     ]
    }
   ],
   "source": [
    "training_set = np.hstack((new_x_train_set, np.resize(new_y_train_set, (new_x_train_set.shape[0], 1))))\n",
    "correct = 0\n",
    "\n",
    "for i, sample in enumerate(x_test):\n",
    "    sample = np.concatenate(sample)\n",
    "    predicted = knn(training_set, sample, 4)\n",
    "    if predicted == y_test[i]:\n",
    "        correct += 1\n",
    "        \n",
    "print(f'success rate: {100*correct/len(x_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = [i > 50 for i in train_set[0]]\n",
    "x = [256 if i else 0 for i in x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f6bcd2caa20>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.resize(x, (28, 28)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
