{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# opens and proccess data for future use\n",
    "with open('iris/iris.data', 'r') as data:\n",
    "    iris_names = ['Iris-setosa', 'Iris-versicolor', 'Iris-virginica']\n",
    "    iris_set = [0, 1, 2]\n",
    "    iris_data = data.read()\n",
    "    iris_data = iris_data[:-1].split('\\n')\n",
    "    \n",
    "    for i in range(len(iris_data)):\n",
    "        iris_data[i] = iris_data[i].split(',')\n",
    "    for i in range(len(iris_data)):\n",
    "        c = iris_data[i][-1]\n",
    "        if c == 'Iris-setosa':\n",
    "            iris_class = 0\n",
    "        elif c == 'Iris-versicolor':\n",
    "            iris_class = 1\n",
    "        elif c == 'Iris-virginica':\n",
    "            iris_class = 2\n",
    "        iris_data[i][-1] = iris_class\n",
    "        iris_data[i] = [float(atribute) for atribute in iris_data[i][:]]\n",
    "        iris_data[i][-1] = int(iris_data[i][-1])\n",
    "    \n",
    "    iris = np.array(iris_data)\n",
    "    iris_features = iris[:,0:-1]\n",
    "    iris_classes = iris[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 1\n",
    "#### Utilizando a base de dados Iris, disponível no link abaixo, e a linguagem de programação de sua preferência, calcule para cada classe:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) O vetor médio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa mean vector = [5.006 3.418 1.464 0.244]\n",
      "Iris-versicolor mean vector = [5.936 2.77  4.26  1.326]\n",
      "Iris-virginica mean vector = [6.588 2.974 5.552 2.026]\n"
     ]
    }
   ],
   "source": [
    "mean_vector = []\n",
    "\n",
    "def calc_mean(dataset):\n",
    "    return np.mean(dataset, axis=0)\n",
    "\n",
    "for i in iris_set:\n",
    "    mean_vector.append(calc_mean(iris_features[np.where(iris_classes == i)]))\n",
    "    print(f'{iris_names[i]} mean vector = {mean_vector[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) O vetor de desvio padrão para cada característica da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa standard deviation vector = [0.35248969 0.3810244  0.17351116 0.1072095 ]\n",
      "Iris-versicolor standard deviation vector = [0.51617115 0.31379832 0.46991098 0.19775268]\n",
      "Iris-virginica standard deviation vector = [0.63587959 0.32249664 0.5518947  0.27465006]\n"
     ]
    }
   ],
   "source": [
    "std_vector = []\n",
    "\n",
    "def calc_stddev(dataset):\n",
    "    return np.std(dataset, axis=0, ddof=1)\n",
    "for i in iris_set:\n",
    "    std_vector.append(calc_stddev(iris_features[np.where(iris_classes == i)]))\n",
    "    print(f'{iris_names[i]} standard deviation vector = {std_vector[i]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) O vetor máximo para cada característica da base de dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa max vector = [5.8 4.4 1.9 0.6]\n",
      "Iris-versicolor max vector = [7.  3.4 5.1 1.8]\n",
      "Iris-virginica max vector = [7.9 3.8 6.9 2.5]\n"
     ]
    }
   ],
   "source": [
    "for i in iris_set:\n",
    "    max_vector = np.max(iris_features[np.where(iris_classes == i)], axis=0)\n",
    "    print(f'{iris_names[i]} max vector = {max_vector}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "d) O vetor mínimo para cada característica da base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa min vector = [4.3 2.3 1.  0.1]\n",
      "Iris-versicolor min vector = [4.9 2.  3.  1. ]\n",
      "Iris-virginica min vector = [4.9 2.2 4.5 1.4]\n"
     ]
    }
   ],
   "source": [
    "for i in iris_set:\n",
    "    min_vector = np.min(iris_features[np.where(iris_classes == i)], axis=0)\n",
    "    print(f'{iris_names[i]} min vector = {min_vector}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "e) A matriz de dispersão\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa disp matrix = \n",
      "[[6.0882 4.9146 0.7908 0.5168]\n",
      " [4.9146 7.1138 0.5724 0.5604]\n",
      " [0.7908 0.5724 1.4752 0.2792]\n",
      " [0.5168 0.5604 0.2792 0.5632]]\n",
      "\n",
      "Iris-versicolor disp matrix = \n",
      "[[13.0552  4.174   8.962   2.7332]\n",
      " [ 4.174   4.825   4.05    2.019 ]\n",
      " [ 8.962   4.05   10.82    3.582 ]\n",
      " [ 2.7332  2.019   3.582   1.9162]]\n",
      "\n",
      "Iris-virginica disp matrix = \n",
      "[[19.8128  4.5944 14.8612  2.4056]\n",
      " [ 4.5944  5.0962  3.4976  2.3338]\n",
      " [14.8612  3.4976 14.9248  2.3924]\n",
      " [ 2.4056  2.3338  2.3924  3.6962]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calc_disp_matrix(dataset):\n",
    "    x = dataset - calc_mean(dataset)\n",
    "    return np.dot(x.T, x)\n",
    "\n",
    "disp_matrix = []\n",
    "\n",
    "for i in iris_set:\n",
    "    disp_matrix.append(calc_disp_matrix(iris_features[np.where(iris_classes == i)]))\n",
    "    print(f'{iris_names[i]} disp matrix = \\n{disp_matrix[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "f) A matriz de covariância"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa covariance matrix = \n",
      "[[0.12424898 0.10029796 0.01613878 0.01054694]\n",
      " [0.10029796 0.14517959 0.01168163 0.01143673]\n",
      " [0.01613878 0.01168163 0.03010612 0.00569796]\n",
      " [0.01054694 0.01143673 0.00569796 0.01149388]]\n",
      "\n",
      "Iris-versicolor covariance matrix = \n",
      "[[0.26643265 0.08518367 0.18289796 0.05577959]\n",
      " [0.08518367 0.09846939 0.08265306 0.04120408]\n",
      " [0.18289796 0.08265306 0.22081633 0.07310204]\n",
      " [0.05577959 0.04120408 0.07310204 0.03910612]]\n",
      "\n",
      "Iris-virginica covariance matrix = \n",
      "[[0.40434286 0.09376327 0.3032898  0.04909388]\n",
      " [0.09376327 0.10400408 0.07137959 0.04762857]\n",
      " [0.3032898  0.07137959 0.30458776 0.04882449]\n",
      " [0.04909388 0.04762857 0.04882449 0.07543265]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calc_cov_matrix(dataset):\n",
    "    n = len(dataset)\n",
    "    return calc_disp_matrix(dataset)/(n-1)\n",
    "\n",
    "cov_matrix = []\n",
    "\n",
    "for i in iris_set:\n",
    "    cov_matrix.append(calc_cov_matrix(iris_features[np.where(iris_classes == i)]))\n",
    "    print(f'{iris_names[i]} covariance matrix = \\n{cov_matrix[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "g) A matriz de correlação\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iris-setosa correlation matrix = \n",
      "[[1.         0.74678037 0.26387409 0.27909157]\n",
      " [0.74678037 1.         0.17669463 0.27997289]\n",
      " [0.26387409 0.17669463 1.         0.30630821]\n",
      " [0.27909157 0.27997289 0.30630821 1.        ]]\n",
      "\n",
      "Iris-versicolor correlation matrix = \n",
      "[[1.         0.52591072 0.75404896 0.54646107]\n",
      " [0.52591072 1.         0.56052209 0.66399872]\n",
      " [0.75404896 0.56052209 1.         0.78666809]\n",
      " [0.54646107 0.66399872 0.78666809 1.        ]]\n",
      "\n",
      "Iris-virginica correlation matrix = \n",
      "[[1.         0.45722782 0.86422473 0.28110771]\n",
      " [0.45722782 1.         0.40104458 0.53772803]\n",
      " [0.86422473 0.40104458 1.         0.32210822]\n",
      " [0.28110771 0.53772803 0.32210822 1.        ]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def calc_corr_matrix(dataset):\n",
    "    stddev = np.array(calc_stddev(dataset))[np.newaxis]\n",
    "    return calc_cov_matrix(dataset) * 1/(stddev.T*stddev)\n",
    "\n",
    "corr_matrix = []\n",
    "\n",
    "for i in iris_set:\n",
    "    corr_matrix.append(calc_corr_matrix(iris_features[np.where(iris_classes == i)]))\n",
    "    print(f'{iris_names[i]} correlation matrix = \\n{corr_matrix[i]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "h) As duas componentes principais de maior magnitude dos dados\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.36158968 -0.65653988]\n",
      " [-0.08226889 -0.72971237]\n",
      " [ 0.85657211  0.1757674 ]\n",
      " [ 0.35884393  0.07470647]]\n"
     ]
    }
   ],
   "source": [
    "eigenvalues, eigenvectors = np.linalg.eig(calc_cov_matrix(iris_features))\n",
    "# eigenvalues are already sorted (uncomment below to check), so we take the 2 first columns in the eigenvectors matrix\n",
    "# print(eigenvalues)\n",
    "# print(eigenvectors)\n",
    "pca_2 = eigenvectors[:,:2] #column vector form of first 2 principal components\n",
    "print(pca_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "i) A projeção dos dados nas duas maiores componentes principais"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.82713597 -5.64133105]\n",
      " [ 2.79595248 -5.14516688]\n",
      " [ 2.62152356 -5.17737812]\n",
      " [ 2.7649059  -5.00359942]\n",
      " [ 2.78275012 -5.64864829]\n",
      " [ 3.23144574 -6.06250644]\n",
      " [ 2.69045242 -5.23261922]\n",
      " [ 2.8848611  -5.48512908]\n",
      " [ 2.62338453 -4.7439257 ]\n",
      " [ 2.83749841 -5.20803203]\n",
      " [ 3.00481631 -5.96665874]\n",
      " [ 2.89820038 -5.33624436]\n",
      " [ 2.72390912 -5.08698354]\n",
      " [ 2.28614265 -4.81144382]\n",
      " [ 2.86779988 -6.50091863]\n",
      " [ 3.12747377 -6.65947808]\n",
      " [ 2.88881689 -6.13281341]\n",
      " [ 2.86302037 -5.6338604 ]\n",
      " [ 3.31226514 -6.19396782]\n",
      " [ 2.92399691 -5.83519737]\n",
      " [ 3.2008114  -5.71259155]\n",
      " [ 2.96810819 -5.75475549]\n",
      " [ 2.2954854  -5.4563393 ]\n",
      " [ 3.20821456 -5.42024641]\n",
      " [ 3.15517201 -5.28351414]\n",
      " [ 3.00342587 -5.17566739]\n",
      " [ 3.0422871  -5.45261105]\n",
      " [ 2.94895215 -5.68940829]\n",
      " [ 2.87152183 -5.6340138 ]\n",
      " [ 2.87849519 -5.1246479 ]\n",
      " [ 2.92288105 -5.11733065]\n",
      " [ 3.10126576 -5.73280374]\n",
      " [ 2.86370642 -6.13470636]\n",
      " [ 2.91418362 -6.41474566]\n",
      " [ 2.83749841 -5.20803203]\n",
      " [ 2.64434325 -5.39191683]\n",
      " [ 2.88611463 -5.92152374]\n",
      " [ 2.83749841 -5.20803203]\n",
      " [ 2.52950043 -4.83447368]\n",
      " [ 2.92102007 -5.55078307]\n",
      " [ 2.74120419 -5.58578315]\n",
      " [ 2.65913202 -4.38185836]\n",
      " [ 2.51304665 -4.98041616]\n",
      " [ 3.105829   -5.51064099]\n",
      " [ 3.30251014 -5.75741976]\n",
      " [ 2.79567791 -5.07204225]\n",
      " [ 2.97376973 -5.82509128]\n",
      " [ 2.6710218  -5.09414739]\n",
      " [ 2.96865734 -5.90100476]\n",
      " [ 2.80743078 -5.42973458]\n",
      " [ 6.79613769 -6.00016292]\n",
      " [ 6.44375385 -5.63392182]\n",
      " [ 6.97540442 -5.81891356]\n",
      " [ 5.6923103  -4.48911979]\n",
      " [ 6.59847758 -5.39011412]\n",
      " [ 6.15177985 -4.89740025]\n",
      " [ 6.60656681 -5.59861494]\n",
      " [ 4.75987596 -4.31361622]\n",
      " [ 6.55464088 -5.54368064]\n",
      " [ 5.50115303 -4.59414886]\n",
      " [ 5.0002569  -4.05223178]\n",
      " [ 6.02244116 -5.21243963]\n",
      " [ 5.77367885 -4.76683043]\n",
      " [ 6.49538764 -5.19036331]\n",
      " [ 5.3364791  -5.06290816]\n",
      " [ 6.43891604 -5.78295994]\n",
      " [ 6.17093589 -4.96274744]\n",
      " [ 5.74588368 -4.9828019 ]\n",
      " [ 6.45370481 -4.77290147]\n",
      " [ 5.5545895  -4.73323428]\n",
      " [ 6.62758382 -5.23050972]\n",
      " [ 5.86812967 -5.2478999 ]\n",
      " [ 6.80781195 -4.98716221]\n",
      " [ 6.43184575 -5.13233337]\n",
      " [ 6.22535131 -5.46510288]\n",
      " [ 6.41098396 -5.64433471]\n",
      " [ 6.84238452 -5.55939325]\n",
      " [ 7.06873937 -5.58211632]\n",
      " [ 6.32379865 -5.15239216]\n",
      " [ 5.20400834 -4.94963712]\n",
      " [ 5.44100021 -4.6121858 ]\n",
      " [ 5.31945861 -4.63723319]\n",
      " [ 5.64633805 -5.00301409]\n",
      " [ 6.89008008 -4.89351859]\n",
      " [ 6.09861795 -4.83143946]\n",
      " [ 6.31854859 -5.50977769]\n",
      " [ 6.73177206 -5.72275907]\n",
      " [ 6.32421089 -4.94404473]\n",
      " [ 5.75653826 -5.0479957 ]\n",
      " [ 5.67585653 -4.63506226]\n",
      " [ 5.97437409 -4.64519718]\n",
      " [ 6.40150354 -5.28091129]\n",
      " [ 5.74022215 -4.91246611]\n",
      " [ 4.80426181 -4.30629897]\n",
      " [ 5.86687614 -4.81150524]\n",
      " [ 5.84247005 -5.10354359]\n",
      " [ 5.88658133 -5.02310171]\n",
      " [ 6.15303338 -5.33379491]\n",
      " [ 4.60287976 -4.56315501]\n",
      " [ 5.80915101 -4.96770721]\n",
      " [ 8.04307008 -5.30288149]\n",
      " [ 6.92541532 -4.73979867]\n",
      " [ 8.12782771 -5.65665902]\n",
      " [ 7.48215804 -5.13359804]\n",
      " [ 7.86110108 -5.27284118]\n",
      " [ 8.90822302 -5.86189178]\n",
      " [ 6.03072634 -4.12337204]\n",
      " [ 8.44334819 -5.66710074]\n",
      " [ 7.83101589 -5.06917556]\n",
      " [ 8.42947733 -6.09510436]\n",
      " [ 7.17327804 -5.55676213]\n",
      " [ 7.31368355 -5.09856912]\n",
      " [ 7.67672196 -5.53000401]\n",
      " [ 6.85593732 -4.53830831]\n",
      " [ 7.0966104  -4.77541668]\n",
      " [ 7.41608668 -5.43354272]\n",
      " [ 7.46059188 -5.35545399]\n",
      " [ 9.00010848 -6.48626828]\n",
      " [ 9.30602996 -5.5679893 ]\n",
      " [ 6.80967292 -4.55370979]\n",
      " [ 7.93951036 -5.6915057 ]\n",
      " [ 6.70944047 -4.70914477]\n",
      " [ 9.01060858 -5.7714972 ]\n",
      " [ 6.89901135 -5.11069274]\n",
      " [ 7.78719675 -5.64811026]\n",
      " [ 8.12553693 -5.87309068]\n",
      " [ 6.76896828 -5.13558673]\n",
      " [ 6.80201275 -5.19829848]\n",
      " [ 7.63419708 -5.10386885]\n",
      " [ 7.8989075  -5.77724298]\n",
      " [ 8.35230402 -5.68746632]\n",
      " [ 8.743686   -6.68524777]\n",
      " [ 7.67008147 -5.0963982 ]\n",
      " [ 6.9544457  -5.17092244]\n",
      " [ 7.2909832  -4.81325894]\n",
      " [ 8.58786472 -6.00048817]\n",
      " [ 7.65632995 -5.45363034]\n",
      " [ 7.41620602 -5.36277124]\n",
      " [ 6.68019657 -5.15022123]\n",
      " [ 7.61899683 -5.68620598]\n",
      " [ 7.82564649 -5.49733258]\n",
      " [ 7.43379398 -5.72399491]\n",
      " [ 6.92541532 -4.73979867]\n",
      " [ 8.07466581 -5.59069823]\n",
      " [ 7.93073432 -5.61822767]\n",
      " [ 7.45536015 -5.50213895]\n",
      " [ 7.03700673 -4.93970288]\n",
      " [ 7.27538903 -5.39324292]\n",
      " [ 7.41297217 -5.43060048]\n",
      " [ 6.90100923 -5.03183702]]\n"
     ]
    }
   ],
   "source": [
    "data_projected = np.dot(iris_features, pca_2)\n",
    "print(data_projected)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 2\n",
    "#### Implemente o algoritmo do k-means na linguagem de programação de sua preferência e inicialize este algoritmo com k=3 centros c1=[5.1,3.5,1.4,0.2], c2=[4.9,3.0,1.4,0.2], c3=[4.7,3.2,1.3,0.2]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def dist(a, b):\n",
    "#     return np.linalg.norm(np.array(a) - np.array(b))\n",
    "\n",
    "def kmeans(dataset, K, centroids, stop_condition):\n",
    "    curr_centroids = centroids\n",
    "    last_centroids = centroids\n",
    "    changes = True\n",
    "#     iterations=0\n",
    "    while changes:\n",
    "        clusters = [[] for i in range(K)]\n",
    "        for i in range(len(dataset)):\n",
    "            distances = [np.linalg.norm(dataset[i] - c) for c in curr_centroids]\n",
    "            clusters[np.argmin(distances)].append(dataset[i])\n",
    "        curr_centroids = [np.mean(c, axis=0) for c in clusters]\n",
    "        changes = (np.linalg.norm(np.array(curr_centroids) - np.array(last_centroids) > stop_condition))\n",
    "        last_centroids = curr_centroids\n",
    "#         iterations+=1\n",
    "\n",
    "#     print(iterations)\n",
    "    return clusters, curr_centroids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Após a convergência, qual o valor dos centros?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.85384615 3.07692308 5.71538462 2.05384615]\n",
      "[5.88360656 2.74098361 4.38852459 1.43442623]\n",
      "[5.006 3.418 1.464 0.244]\n"
     ]
    }
   ],
   "source": [
    "c1 = [5.1,3.5,1.4,0.2]\n",
    "c2= [4.9,3.0,1.4,0.2]\n",
    "c3= [4.7,3.2,1.3,0.2]\n",
    "\n",
    "clusters, centroids = kmeans(iris_features, 3, [c1, c2, c3], 0)\n",
    "for c in centroids:\n",
    "    print(c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Qual o centro mais próximo do centro da classe “Iris-setosa”\n",
    "<br />\n",
    "c) Qual o centro mais próximo do centro da classe “Iris-versicolor”\n",
    "<br />\n",
    "d) Qual o centro mais próximo do centro da classe “Iris-virginica”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a) Setosa nearest centroid:\n",
      "[5.006 3.418 1.464 0.244]\n",
      "\n",
      "a) Versicolor nearest centroid:\n",
      "[5.88360656 2.74098361 4.38852459 1.43442623]\n",
      "\n",
      "a) Virginica nearest centroid:\n",
      "[6.85384615 3.07692308 5.71538462 2.05384615]\n"
     ]
    }
   ],
   "source": [
    "setosa_centroid = calc_mean(iris_features[np.where(iris_classes == 0)])\n",
    "near_setosa = centroids[np.argmin([np.linalg.norm(c - setosa_centroid) for c in centroids])]\n",
    "print('a) Setosa nearest centroid:')\n",
    "# print(setosa_centroid)\n",
    "print(near_setosa)\n",
    "print()\n",
    "\n",
    "versicolor_centroid = calc_mean(iris_features[np.where(iris_classes == 1)])\n",
    "near_versicolor = centroids[np.argmin([np.linalg.norm(c - versicolor_centroid) for c in centroids])]\n",
    "print('a) Versicolor nearest centroid:')\n",
    "# print(versicolor_centroid)\n",
    "print(near_versicolor)\n",
    "print()\n",
    "\n",
    "virginica_centroid = calc_mean(iris_features[np.where(iris_classes == 2)])\n",
    "near_virginica = centroids[np.argmin([np.linalg.norm(c - virginica_centroid) for c in centroids])]\n",
    "print('a) Virginica nearest centroid:')\n",
    "# print(virginica_centroid)\n",
    "print(near_virginica)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 3\n",
    "#### Implemente o algoritmo do KNN na linguagem de programação de sua preferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_common(lst):\n",
    "    return max(set(lst), key=lst.count)\n",
    "\n",
    "def knn(dataset, sample, k):\n",
    "    #dataset: (attributes, class labels)\n",
    "    data = dataset[:, 0:-1]\n",
    "    labels = dataset[:, -1]\n",
    "    test_sample = np.array(sample)\n",
    "    \n",
    "    total_dist = data - test_sample                          # numpy automatically creates a repeated array of test_sample\n",
    "    norm = np.sum(total_dist*total_dist, axis=1)\n",
    "    neighbors = list(zip(norm, labels))                      # create list of tuples (square of distance, label of class)\n",
    "    neighbors = sorted(neighbors, key=lambda tup: tup[0])    # sort neighbors by distance\n",
    "    closest_n = [atribute[1] for atribute in neighbors[:k]]\n",
    "    \n",
    "    return most_common(closest_n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9333333333333333\n"
     ]
    }
   ],
   "source": [
    "training, test = train_test_split(iris, test_size = 0.3)\n",
    "# print(test[0][0])\n",
    "# print(trainning[0])\n",
    "success_rate = 0\n",
    "for sample in test:\n",
    "    n = knn(training, sample[:-1], 3)\n",
    "    success_rate += (n == sample[-1])\n",
    "\n",
    "success_rate /= len(test)\n",
    "print(success_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 4\n",
    "#### Implemente um classificador de distância mínima na linguagem de sua preferência."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def minimum_distance_classifier(training_set, sample):\n",
    "    data = training_set[:, 0:-1]\n",
    "    labels = training_set[:,-1]\n",
    "    \n",
    "    classes = set([int(i) for i in labels])\n",
    "    centroids = [[] for i in range(len(classes))]\n",
    "    for i in classes:\n",
    "        centroids[i] = calc_mean(data[np.where(labels == i)])\n",
    "    closest_centroid = np.argmin([np.linalg.norm(c - sample) for c in centroids])\n",
    "    \n",
    "    return closest_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "training, test = train_test_split(iris, test_size = 0.3)\n",
    "# print(test[0][0])\n",
    "# print(trainning[0])\n",
    "success_rate = 0\n",
    "for sample in test:\n",
    "    n = minimum_distance_classifier(training, sample[:-1])\n",
    "    success_rate += (n == sample[-1])\n",
    "\n",
    "success_rate /= len(test)\n",
    "print(success_rate)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 5\n",
    "#### Implemente uma função discriminante utilizando o log da probabilidade a posteriori para cada uma das classes da base de dados Iris.\n",
    "\n",
    "<center>\n",
    "    $g_i(x) = -\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu_i})^T \\mathbf{\\Sigma_i^{-1}}(\\mathbf{x}-\\mathbf{\\mu_i})- \\frac{d}{2}ln(2\\pi)-\\frac{1}{2}ln(\\left | \\mathbf{\\Sigma_i} \\right |) + ln(P(\\omega_i))$\n",
    "</center>\n",
    "\n",
    "Retirando o termo comum a todas as classes:\n",
    "\n",
    "<center>\n",
    "    $g_i(x) = -\\frac{1}{2}(\\mathbf{x}-\\mathbf{\\mu_i})^T \\mathbf{\\Sigma_i^{-1}}(\\mathbf{x}-\\mathbf{\\mu_i})-\\frac{1}{2}ln(\\left | \\mathbf{\\Sigma_i} \\right |) + ln(P(\\omega_i))$\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_discriminant(sample, class_mean, class_cov, class_prob):\n",
    "    cov_inv = np.linalg.inv(class_cov)\n",
    "    g = -0.5*np.dot(np.dot((sample - class_mean), cov_inv), (sample - class_mean).T) - 0.5*np.log(np.linalg.det(class_cov)) + np.log(class_prob)\n",
    "    \n",
    "    return g"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 6\n",
    "\n",
    "#### Implemente um classificador bayesiano para a base de dados Iris."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayesian_classifier(training_set, sample):\n",
    "    data = training_set[:, 0:-1]\n",
    "    labels = training_set[:,-1]\n",
    "    \n",
    "    classes = set([int(i) for i in labels])\n",
    "    set_size = len(data)\n",
    "    g = [[] for i in classes]\n",
    "    \n",
    "    for i in classes:\n",
    "        p_priori = len(data[np.where(labels == i)])/set_size\n",
    "        g[i] = log_discriminant(sample, calc_mean(data[np.where(labels == i)]), calc_cov_matrix(data[np.where(labels == i)]), p_priori)\n",
    "#         print(f'g[{i}] = {g[i]}')\n",
    "#         print(g[i])\n",
    "    \n",
    "    return np.argmax(np.array(g))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9555555555555556\n"
     ]
    }
   ],
   "source": [
    "training, test = train_test_split(iris, test_size = 0.3)\n",
    "# print(test[0][0])\n",
    "# print(trainning[0])\n",
    "success_rate_bayesian = 0\n",
    "\n",
    "for sample in test:\n",
    "    n = bayesian_classifier(training, sample[:-1])\n",
    "    success_rate_bayesian += (n == sample[-1])\n",
    "    \n",
    "success_rate_bayesian /= len(test)\n",
    "print(success_rate_bayesian)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 7\n",
    "#### Implemente um classificador bayesiano para a base de dados Iris projetada sobre as duas maiores componentes principais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9111111111111111\n"
     ]
    }
   ],
   "source": [
    "# concatenates classes to PCA components of data\n",
    "new_data_projected = np.concatenate((data_projected, np.array(iris_classes[np.newaxis]).T), 1)\n",
    "\n",
    "training, test = train_test_split(new_data_projected, test_size = 0.3)\n",
    "# print(test[0][0])\n",
    "# print(trainning[0])\n",
    "success_rate_bayesian_PCA = 0\n",
    "\n",
    "for sample in test:\n",
    "    n = bayesian_classifier(training, sample[:-1])\n",
    "    success_rate_bayesian_PCA += (n == sample[-1])\n",
    "    \n",
    "success_rate_bayesian_PCA /= len(test)\n",
    "print(success_rate_bayesian_PCA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 8\n",
    "#### Determine o erro percentual e o desvio padrão do erro(quando for possível) nos conjuntos de treinamento e validação dos classificadores implementados nas questões 3,4, 6 e 7 utilizando os seguintes métodos de particionamento de dados:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Hold-out com 90% das amostras para treinamento e 10% para validação;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_error(classifier, training, test, extrArgs = []):\n",
    "    error_rate = 0\n",
    "    \n",
    "    for sample in test:\n",
    "        if classifier == knn:\n",
    "            n = classifier(training, sample[:-1], extrArgs[0])\n",
    "        else:\n",
    "            n = classifier(training, sample[:-1])\n",
    "        error_rate[n][sample[-1]] += not(n == sample[-1])\n",
    "        \n",
    "    return error_rate/len(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN error rate: 0.06666666666666667\n",
      "Minimum distance error rate: 0.06666666666666667\n",
      "Bayesian error rate: 0.0\n"
     ]
    }
   ],
   "source": [
    "training, test = train_test_split(iris, test_size = 0.1)\n",
    "\n",
    "print(f'KNN error rate: {evaluate_error(knn, training, test, [3])}')\n",
    "print(f'Minimum distance error rate: {evaluate_error(minimum_distance_classifier, training, test)}')\n",
    "print(f'Bayesian error rate: {evaluate_error(bayesian_classifier, training, test)}')\n",
    "# print(f'Bayesian error rate: {holdout(bayesian_classifier, iris, 0.1)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b) Cross-validation 10-folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_folds(dataset, k):\n",
    "    data_cpy = dataset.copy()\n",
    "    np.random.shuffle(data_cpy)            # desordena conjunto de dados\n",
    "    folds = np.split(data_cpy, k)          # divide os grupos\n",
    "    return folds\n",
    "\n",
    "def kfolds(classifier, dataset, k, extrArgs = []):\n",
    "    folds = split_folds(dataset, k)\n",
    "    error_array = []\n",
    "\n",
    "    for i, fold in enumerate(folds):\n",
    "        folds_cpy = folds.copy()           # cria cópia dos grupos\n",
    "        test = folds_cpy.pop(i)            # separa grupo i para teste\n",
    "        training = np.vstack(folds_cpy)    # agrupa demais grupos para treinamento\n",
    "        error_array = np.append(error_array, evaluate_error(classifier, training, test, extrArgs))\n",
    "    \n",
    "    return np.mean(error_array), np.std(error_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN error rate (0.04, 0.044221663871405324)\n",
      "Minimum distance error rate (0.08666666666666667, 0.05206833117271103)\n",
      "Bayesian error rate (0.02, 0.03055050463303893)\n"
     ]
    }
   ],
   "source": [
    "print(f'KNN error rate {kfolds(knn, iris, 10, [3])}')\n",
    "print(f'Minimum distance error rate {kfolds(minimum_distance_classifier, iris, 10)}')\n",
    "print(f'Bayesian error rate {kfolds(bayesian_classifier, iris, 10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "c) Monte-Carlo Cross Validation com 90% das amostras para treinamento e 10% para validação"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def monte_carlo(classifier, dataset, test_size, k, extrArgs = []):\n",
    "    error_array = []\n",
    "    \n",
    "    for i in range(k):\n",
    "        training, test = train_test_split(dataset, test_size = test_size)\n",
    "        error_array = np.append(error_array, evaluate_error(classifier, training, test, extrArgs))\n",
    "    \n",
    "    return np.mean(error_array), np.std(error_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN error rate (0.02, 0.030550504633038933)\n",
      "Minimum distance error rate (0.09333333333333334, 0.0679869268479038)\n",
      "Bayesian error rate (0.02, 0.03055050463303893)\n"
     ]
    }
   ],
   "source": [
    "print(f'KNN error rate {monte_carlo(knn, iris, 0.1, 10, [3])}')\n",
    "print(f'Minimum distance error rate {monte_carlo(minimum_distance_classifier, iris, 0.1, 10)}')\n",
    "print(f'Bayesian error rate {monte_carlo(bayesian_classifier, iris, 0.1, 10)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questão 9\n",
    "#### Repita as avaliações da questão 6, calculando a matriz de confusão do erro percentual para cada um dos métodos de particionamento (Houldout, Cross-Validation 10-folds, Monte Carlo Cross-Validation).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_confusion_matrix(classifier, training, test, extrArgs = []):\n",
    "    classes = set([i[-1] for i in training])\n",
    "    n_classes = len(classes)\n",
    "    confusion_matrix = np.zeros((n_classes, n_classes))\n",
    "    \n",
    "    for sample in test:\n",
    "        if classifier == knn:\n",
    "            n = classifier(training, sample[:-1], extrArgs[0])\n",
    "        else:\n",
    "            n = classifier(training, sample[:-1])\n",
    "        confusion_matrix[int(n)][int(sample[-1])] += 1\n",
    "        \n",
    "    return 100*confusion_matrix/confusion_matrix.sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN confusion matrix: \n",
      "[[35.55555556  0.          0.        ]\n",
      " [ 0.         33.33333333  0.        ]\n",
      " [ 0.          4.44444444 26.66666667]]\n",
      "\n",
      "Minimum distance confusion matrix: \n",
      "[[35.55555556  0.          0.        ]\n",
      " [ 0.         31.11111111  2.22222222]\n",
      " [ 0.          4.44444444 26.66666667]]\n",
      "\n",
      "Bayesian confusion matrix: \n",
      "[[35.55555556  0.          0.        ]\n",
      " [ 0.         31.11111111  2.22222222]\n",
      " [ 0.          0.         31.11111111]]\n"
     ]
    }
   ],
   "source": [
    "training, test = train_test_split(iris, test_size = 0.3)\n",
    "\n",
    "print(f'KNN confusion matrix: \\n{calc_confusion_matrix(knn, training, test, [3]).T}\\n')\n",
    "print(f'Minimum distance confusion matrix: \\n{calc_confusion_matrix(minimum_distance_classifier, training, test).T}\\n')\n",
    "print(f'Bayesian confusion matrix: \\n{calc_confusion_matrix(bayesian_classifier, training, test).T}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
